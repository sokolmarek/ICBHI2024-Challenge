{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-23T20:37:43.743592Z",
     "start_time": "2024-09-23T20:37:43.730585Z"
    }
   },
   "source": [
    "import gc\n",
    "\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dropout, Conv2D, MaxPooling2D, Input, Flatten, Dense\n",
    "from keras.layers import MaxPooling1D, Conv1D, concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "# USE MIXED PRECISION \n",
    "MIX = True\n",
    "if MIX:\n",
    "    tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "    print(\"Mixed precision enabled\")\n",
    "else:\n",
    "    print(\"Using full precision\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision enabled\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T20:32:53.923830Z",
     "start_time": "2024-09-23T20:32:53.878832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FS = 400\n",
    "s, e = 15, 25\n",
    "a, b = 0, 246\n",
    "data = np.load(\"../data/processed/train_img.npy\", allow_pickle=True).item()\n",
    "\n",
    "fmri = data[\"fMRI\"]\n",
    "rsp = data[\"RSP\"]\n",
    "ppg = data[\"PPG\"]\n",
    "bio = np.concatenate((rsp, ppg), axis=-1)\n",
    "\n",
    "# rsp = data[\"RSP\"][:, 5*FS:]\n",
    "# ppg = data[\"PPG\"][:, 5*FS:]\n",
    "# bio = np.stack((rsp[:, ::10], ppg[:, ::10]), axis=-1)\n",
    "train = np.swapaxes(fmri[:, a:b, s:e], 1, 2)\n",
    "# train = np.expand_dims(np.swapaxes(fmri[:, :, :], 1, 2),  axis=-1)\n",
    "\n",
    "subject = data[\"subject\"]\n",
    "target = data[\"class\"].astype(int) + 1\n",
    "level = data[\"level\"]\n",
    "\n",
    "print(f\"Data shape: {train.shape}\")\n",
    "print(f\"Bio shape: {bio.shape}\")\n",
    "print(f\"Subject shape: {subject.shape}\")\n",
    "print(f\"Target shape: {target.shape}\")\n",
    "print(f\"Level shape: {level.shape}\")\n",
    "print(np.unique(target))"
   ],
   "id": "eb5ee0e91582678f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (480, 10, 246)\n",
      "Bio shape: (480, 64, 64, 4)\n",
      "Subject shape: (480,)\n",
      "Target shape: (480,)\n",
      "Level shape: (480,)\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T20:32:54.064690Z",
     "start_time": "2024-09-23T20:32:54.049692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_test = np.load(\"../data/processed/test_img.npy\", allow_pickle=True).item()\n",
    "test_idx = np.where(~np.isnan(data_test[\"class\"]))[0]\n",
    "\n",
    "y_test = data_test[\"class\"][test_idx].astype(int) + 1\n",
    "y_test_level = data_test[\"level\"][test_idx]\n",
    "fmri_test = np.swapaxes(data_test[\"fMRI\"][:, a:b, s:e], 1, 2)\n",
    "bio_test = np.concatenate((data_test[\"RSP\"][:], data_test[\"PPG\"][:]), axis=-1)\n",
    "\n",
    "print(f\"fMRI shape: {fmri_test.shape}\")\n",
    "print(f\"Bio shape: {bio_test.shape}\")\n",
    "print(f\"Test target shape: {y_test.shape}\")\n",
    "print(\"Level shape:\", y_test_level.shape)\n",
    "print(np.unique(y_test))"
   ],
   "id": "5a5d3559773a6bb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fMRI shape: (120, 10, 246)\n",
      "Bio shape: (120, 64, 64, 4)\n",
      "Test target shape: (36,)\n",
      "Level shape: (36,)\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T20:33:10.093199Z",
     "start_time": "2024-09-23T20:33:10.076199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_model():\n",
    "    # Define input shapes\n",
    "    input_shape_1d = (train.shape[1], train.shape[2])  # Temporal input: 25 time points for 246 brain regions\n",
    "    input_shape_2d = (train.shape[1], train.shape[2], 1)  # Spatial input: 25x246 spatial grid\n",
    "    l2_reg = 1e-2\n",
    "    dp = 0.25\n",
    "\n",
    "    # 1D CNN for temporal data\n",
    "    input_1d = Input(shape=input_shape_1d)\n",
    "    # x1 = TimeDistributed(Dense(128, kernel_regularizer=l2(l2_reg), activation=\"relu\"))(input_1d)\n",
    "    # x1 = LSTM(64, return_sequences=False, kernel_regularizer=l2(l2_reg))(input_1d)\n",
    "    # x1 = Dropout(dp)(x1)\n",
    "\n",
    "    x1 = Conv1D(filters=32, kernel_size=3, padding=\"valid\", activation=\"relu\", kernel_regularizer=l2(l2_reg))(input_1d)\n",
    "    x1 = Conv1D(filters=64, kernel_size=5, padding=\"valid\", activation=\"relu\", kernel_regularizer=l2(l2_reg))(x1)\n",
    "    x1 = MaxPooling1D(pool_size=2)(x1)\n",
    "    x1 = Dropout(dp)(x1)\n",
    "    x1 = Flatten()(x1)\n",
    "\n",
    "    # 2D CNN for spatial data\n",
    "    input_2d = Input(shape=input_shape_2d)\n",
    "    x2 = Conv2D(filters=64, kernel_size=3, padding=\"valid\", activation=\"relu\", kernel_regularizer=l2(l2_reg))(input_2d)\n",
    "    x2 = Conv2D(filters=128, kernel_size=5, padding=\"valid\", activation=\"relu\", kernel_regularizer=l2(l2_reg))(x2)\n",
    "    x2 = MaxPooling2D(pool_size=2)(x2)\n",
    "    x2 = Dropout(dp)(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "\n",
    "    # Concatenate the outputs of the two branches\n",
    "    combined = concatenate([x1, x2])\n",
    "\n",
    "    # Fully connected layers\n",
    "    fc = Dense(256, activation=\"relu\", kernel_regularizer=l2(l2_reg))(combined)\n",
    "    fc = Dropout(dp)(fc)\n",
    "    fc = Dense(128, activation=\"relu\", kernel_regularizer=l2(l2_reg))(fc)\n",
    "\n",
    "    # Output layer\n",
    "    class_output = Dense(3, activation=\"softmax\", name=\"class\")(fc)\n",
    "    level_output = Dense(1, activation=\"linear\", name=\"level\")(fc)\n",
    "\n",
    "    model = Model(inputs=[input_1d, input_2d], outputs=[class_output, level_output])\n",
    "\n",
    "    # optimizer = RMSprop(learning_rate=1e-3, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    optimizer = Adam(learning_rate=1e-4)\n",
    "    # optimizer = SGD(learning_rate=0.1, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=optimizer, loss={\"class\": \"categorical_crossentropy\", \"level\": \"mae\"},\n",
    "                  metrics={\"class\": \"accuracy\", \"level\": \"mae\"})\n",
    "\n",
    "    return model"
   ],
   "id": "551242fd03233c26",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T20:43:02.199872Z",
     "start_time": "2024-09-23T20:41:27.800877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "val_acc = []\n",
    "test_count = []\n",
    "test_score = []\n",
    "preds = []\n",
    "rocauc_test = []\n",
    "test_acc = []\n",
    "val_mae = []\n",
    "val_smape = []\n",
    "test_smape = []\n",
    "accs = []\n",
    "\n",
    "X = train\n",
    "y = target\n",
    "groups = subject\n",
    "\n",
    "loso_tidx = np.load(\"../data/loso_tidx.npy\", allow_pickle=True)\n",
    "loso_vidx = np.load(\"../data/loso_vidx.npy\", allow_pickle=True)\n",
    "\n",
    "cv = LeaveOneGroupOut()\n",
    "# cv = GroupKFold(n_splits=5)\n",
    "# cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for i, (tidx, vidx) in enumerate(cv.split(X, y, groups)):\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"### Fold {i + 1}\")\n",
    "\n",
    "    # X_train, X_val = X[tidx], X[vidx]\n",
    "    # y_train, y_val = to_categorical(y[tidx]), to_categorical(y[vidx])\n",
    "    # y_train_level, y_val_level = level[tidx], level[vidx]\n",
    "    \n",
    "    X_train, X_val = X[loso_tidx[i]], X[loso_vidx[i]]\n",
    "    y_train, y_val = to_categorical(y[loso_tidx[i]]), to_categorical(y[loso_vidx[i]])\n",
    "    y_train_level, y_val_level = level[loso_tidx[i]], level[loso_vidx[i]]\n",
    "\n",
    "    print(f\"### train size {len(tidx)}, valid size {len(vidx)}\")\n",
    "    print(\"#\" * 50)\n",
    "\n",
    "    # Callbacks\n",
    "    # mdl_ch = ModelCheckpoint(f\"../results/models/CNN_v1_f{i + 1}.h5\", monitor=\"val_class_accuracy\",\n",
    "    #                          save_best_only=True, save_weights_only=True, verbose=0)\n",
    "    # lr_red = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, min_lr=1e-6)\n",
    "    # lr_sched = LearningRateScheduler(lrfn)\n",
    "    # earlystop = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "    # Fit the model\n",
    "    K.clear_session()\n",
    "    model = build_model()\n",
    "    history = model.fit([X_train, np.expand_dims(X_train, axis=-1)], [y_train, y_train_level],\n",
    "                        batch_size=batch_size,\n",
    "                        validation_batch_size=2 * batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=([X_val, np.expand_dims(X_val, axis=-1)], [y_val, y_val_level]),\n",
    "                        callbacks=[], verbose=0)\n",
    "\n",
    "    val_acc.append(np.max(model.history.history[\"val_class_accuracy\"]))\n",
    "    val_mae.append(np.min(model.history.history[\"val_level_mae\"]))\n",
    "\n",
    "    # Inference on test set\n",
    "    Y_pred = model.predict([fmri_test, np.expand_dims(fmri_test, axis=-1)], verbose=0)\n",
    "    preds.append(Y_pred[0])\n",
    "    pred_classes = np.argmax(Y_pred[0], axis=1) - 1\n",
    "    true_classes = data_test[\"class\"][test_idx].astype(int)\n",
    "    class_error = 1 - (np.sum(pred_classes[test_idx] == true_classes) / len(true_classes))\n",
    "    test_count.append(np.sum(pred_classes[test_idx] == true_classes))\n",
    "    accs.append(accuracy_score(true_classes, pred_classes[test_idx]))\n",
    "    test_score.append(class_error)\n",
    "\n",
    "    # Plot the training history\n",
    "    # plt.figure(figsize=(12, 4))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "    # plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    # plt.legend()\n",
    "    # plt.title(\"Loss over Epochs\")\n",
    "    # \n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "    # plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    # plt.legend()\n",
    "    # plt.title(\"Accuracy over Epochs\")\n",
    "    # plt.show()\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(np.round(val_acc, 2))\n",
    "print(\"#\" * 50)\n",
    "print(\"Acc stats:\")\n",
    "print(np.mean(val_acc), np.std(val_acc), np.min(val_acc), np.max(val_acc))\n",
    "print(\"MAE stats:\")\n",
    "print(np.mean(val_mae), np.std(val_mae), np.min(val_mae), np.max(val_mae))\n",
    "print(\"#\" * 100)\n",
    "print(\"Test stats:\")\n",
    "print(f\"Correct predictions: {test_count}\")\n",
    "print(f\"Scores: {test_score}\")\n"
   ],
   "id": "503e79a10674541",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "### Fold 1\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 2\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 3\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 4\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 5\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 6\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 7\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 8\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 9\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 10\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 11\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 12\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 13\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 14\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 15\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "##################################################\n",
      "### Fold 16\n",
      "### train size 450, valid size 30\n",
      "##################################################\n",
      "####################################################################################################\n",
      "[0.63 0.67 0.67 0.7  0.6  0.73 0.73 0.73 0.67 0.73 0.73 0.7  0.67 0.7\n",
      " 0.73 0.67]\n",
      "##################################################\n",
      "Acc stats:\n",
      "0.6916666775941849 0.03996526186571288 0.6000000238418579 0.7333333492279053\n",
      "MAE stats:\n",
      "1.7246173955500126 0.44551839149560546 0.9315569996833801 2.471280336380005\n",
      "####################################################################################################\n",
      "Test stats:\n",
      "Correct predictions: [24, 27, 23, 26, 25, 26, 24, 27, 26, 26, 25, 26, 26, 24, 26, 26]\n",
      "Scores: [0.33333333333333337, 0.25, 0.36111111111111116, 0.2777777777777778, 0.3055555555555556, 0.2777777777777778, 0.33333333333333337, 0.25, 0.2777777777777778, 0.2777777777777778, 0.3055555555555556, 0.2777777777777778, 0.2777777777777778, 0.33333333333333337, 0.2777777777777778, 0.2777777777777778]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T20:51:08.563452Z",
     "start_time": "2024-09-23T20:51:08.229840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = np.mean(preds, axis=0)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test - 1, np.argmax(preds[-1][test_idx], axis=1) - 1, cmap=plt.cm.Blues)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ],
   "id": "6e03aec8b9fb18c6",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mmean(preds, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      3\u001B[0m ConfusionMatrixDisplay\u001B[38;5;241m.\u001B[39mfrom_predictions(y_test \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, np\u001B[38;5;241m.\u001B[39margmax(preds[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][test_idx], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, cmap\u001B[38;5;241m=\u001B[39mplt\u001B[38;5;241m.\u001B[39mcm\u001B[38;5;241m.\u001B[39mBlues)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mgrid(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Phase2 Test labels accuracy\n",
    "np.mean(accs)"
   ],
   "id": "c3eac20522268df2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
